# TCC Therapy Chatbot - AWS Lambda

Um chatbot especializado em Terapia Cognitivo-Comportamental (TCC) executando em AWS Lambda com Small Language Models (SLMs).

## ğŸ¯ CaracterÃ­sticas

- **Especializado em TCC**: Respostas baseadas em tÃ©cnicas de Terapia Cognitivo-Comportamental
- **Respostas Contextuais**: Diferentes respostas baseadas no tipo de problema (ansiedade, depressÃ£o, trabalho, relacionamentos)
- **Modo Demo**: Funciona sem Ollama para demonstraÃ§Ãµes
- **AnÃ¡lise TCC**: Identifica padrÃµes cognitivos e sugere tÃ©cnicas terapÃªuticas
- **SugestÃµes de Tarefas**: Oferece "homework" terapÃªutico personalizado

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway   â”‚â”€â”€â”€â–¶â”‚   AWS Lambda     â”‚â”€â”€â”€â–¶â”‚   Ollama (CPU)  â”‚
â”‚                 â”‚    â”‚   (Python 3.11)  â”‚    â”‚   + TinyLlama   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
slm-lambda-project/
â”œâ”€â”€ src/                          # CÃ³digo fonte
â”‚   â”œâ”€â”€ lambda_function.py        # Handler principal do Lambda
â”‚   â”œâ”€â”€ model_manager.py          # Gerenciamento do modelo e Ollama
â”‚   â”œâ”€â”€ tcc_context.py            # Contexto e anÃ¡lise TCC
â”‚   â”œâ”€â”€ utils.py                  # UtilitÃ¡rios e validaÃ§Ã£o
â”‚   â””â”€â”€ requirements.txt          # DependÃªncias Python
â”œâ”€â”€ infrastructure/               # Infraestrutura Terraform
â”‚   â”œâ”€â”€ lambda.tf                 # Recursos Lambda
â”‚   â”œâ”€â”€ api-gateway.tf            # API Gateway
â”‚   â”œâ”€â”€ variables.tf              # VariÃ¡veis Terraform
â”‚   â”œâ”€â”€ outputs.tf                # Outputs Terraform
â”‚   â”œâ”€â”€ providers.tf              # Providers Terraform
â”‚   â””â”€â”€ terraform.tfvars.example  # Exemplo de variÃ¡veis
â”œâ”€â”€ scripts/                      # Scripts de deploy e teste
â”‚   â”œâ”€â”€ deploy.sh                 # Script de deploy automÃ¡tico
â”‚   â””â”€â”€ test.sh                   # Script de teste
â”œâ”€â”€ Dockerfile                    # Container para desenvolvimento
â”œâ”€â”€ Dockerfile.lambda             # Container otimizado para Lambda
â”œâ”€â”€ ollama-config.yaml            # ConfiguraÃ§Ã£o do Ollama
â”œâ”€â”€ config.example.env            # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ README.md                     # DocumentaÃ§Ã£o principal
â”œâ”€â”€ USAGE.md                      # Guia de uso detalhado
â”œâ”€â”€ CONTRIBUTING.md               # Guia de contribuiÃ§Ã£o
â”œâ”€â”€ LICENSE                       # LicenÃ§a MIT
â””â”€â”€ .gitignore                    # Arquivos ignorados
```

## ğŸš€ Como Usar

### 1. Deploy Local (Desenvolvimento)

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd slm-lambda-project

# Instale dependÃªncias
pip install -r src/requirements.txt

# Execute localmente
python src/lambda_function.py
```

### 2. Deploy AWS Lambda (Recomendado)

#### Deploy AutomÃ¡tico com Script

```bash
# Configure suas credenciais AWS
aws configure

# Execute o script de deploy
./scripts/deploy.sh

# Ou com parÃ¢metros customizados
./scripts/deploy.sh --region us-east-1 --function-name meu-chatbot
```

#### Deploy Manual com Terraform

```bash
# Configure as variÃ¡veis
cd infrastructure
cp terraform.tfvars.example terraform.tfvars
# Edite terraform.tfvars com seus valores

# Deploy da infraestrutura
terraform init
terraform plan
terraform apply

# Build e push da imagem Docker
docker build -f Dockerfile.lambda -t tcc-chatbot .
aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin <account>.dkr.ecr.us-east-2.amazonaws.com
docker tag tcc-chatbot:latest <account>.dkr.ecr.us-east-2.amazonaws.com/tcc-chatbot:latest
docker push <account>.dkr.ecr.us-east-2.amazonaws.com/tcc-chatbot:latest

# Atualizar Lambda
aws lambda update-function-code \
  --function-name tcc-chatbot \
  --image-uri <account>.dkr.ecr.us-east-2.amazonaws.com/tcc-chatbot:latest
```

### 3. Deploy Manual (Sem Terraform)

#### OpÃ§Ã£o A: Container Image

```bash
# Build da imagem
docker build -f Dockerfile.lambda -t tcc-chatbot .

# Tag para ECR
docker tag tcc-chatbot:latest <account>.dkr.ecr.<region>.amazonaws.com/tcc-chatbot:latest

# Push para ECR
docker push <account>.dkr.ecr.<region>.amazonaws.com/tcc-chatbot:latest

# Deploy no Lambda
aws lambda create-function \
  --function-name tcc-chatbot \
  --package-type Image \
  --code ImageUri=<account>.dkr.ecr.<region>.amazonaws.com/tcc-chatbot:latest \
  --role arn:aws:iam::<account>:role/lambda-execution-role \
  --timeout 300 \
  --memory-size 3008
```

#### OpÃ§Ã£o B: ZIP Package

```bash
# Crie um ZIP com o cÃ³digo
cd src
zip -r ../tcc-chatbot.zip .

# Deploy no Lambda
aws lambda create-function \
  --function-name tcc-chatbot \
  --runtime python3.11 \
  --role arn:aws:iam::<account>:role/lambda-execution-role \
  --handler lambda_function.lambda_handler \
  --zip-file fileb://tcc-chatbot.zip \
  --timeout 300 \
  --memory-size 3008
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
MODEL_NAME=tinyllama              # Nome do modelo Ollama
OLLAMA_HOST=0.0.0.0:11434        # Host do Ollama
TEMPERATURE=0.7                   # Temperatura para geraÃ§Ã£o
MAX_TOKENS=512                    # MÃ¡ximo de tokens
TCC_MODE=true                     # Ativar modo TCC
OLLAMA_CPU_ONLY=1                 # Usar apenas CPU
```

### ConfiguraÃ§Ã£o do Ollama

O arquivo `ollama-config.yaml` contÃ©m configuraÃ§Ãµes para o Ollama:

```yaml
model: tinyllama
temperature: 0.7
max_tokens: 512
cpu_only: true
```

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /health
```

**Resposta:**
```json
{
  "status": "healthy",
  "model": "tinyllama",
  "model_status": {
    "loaded": true,
    "demo_mode": false,
    "tcc_enabled": true
  },
  "timestamp": 1757462764
}
```

### Inference
```bash
POST /inference
Content-Type: application/json

{
  "prompt": "Estou me sentindo muito ansioso hoje",
  "max_tokens": 512,
  "temperature": 0.7
}
```

**Resposta:**
```json
{
  "response": "Entendo que vocÃª estÃ¡ se sentindo ansioso(a)...",
  "tokens_generated": 182,
  "inference_time": 1.43,
  "model": "tinyllama",
  "timestamp": 1757462750,
  "tcc_analysis": {
    "cognitive_patterns": ["Pensamento absolutista: 'nÃ£o consigo'"],
    "emotional_indicators": ["ansiedade"],
    "suggested_techniques": ["ReestruturaÃ§Ã£o cognitiva", "TÃ©cnicas de relaxamento"]
  },
  "homework_suggestions": [
    "Registre seus pensamentos automÃ¡ticos em um diÃ¡rio por uma semana"
  ]
}
```

## ğŸ§  Tipos de Resposta TCC

O sistema identifica automaticamente o contexto e fornece respostas especializadas:

### Ansiedade
- TÃ©cnicas de respiraÃ§Ã£o
- Questionamento de pensamentos
- ExposiÃ§Ã£o gradual

### DepressÃ£o
- AtivaÃ§Ã£o comportamental
- Planejamento de atividades
- TÃ©cnicas de reestruturaÃ§Ã£o cognitiva

### Trabalho
- GestÃ£o de estresse
- Estabelecimento de limites
- TÃ©cnicas de priorizaÃ§Ã£o

### Relacionamentos
- ComunicaÃ§Ã£o assertiva
- Questionamento de pensamentos sociais
- Foco na autenticidade

### Casos Gerais
- Respostas variadas baseadas em TCC
- TÃ©cnicas de questionamento cognitivo
- Foco em soluÃ§Ãµes prÃ¡ticas

## ğŸ§ª Testando

```bash
# Teste local
curl -X POST http://localhost:8080/inference \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Estou passando por um momento difÃ­cil no trabalho"}'

# Teste AWS
curl -X POST https://<api-id>.execute-api.<region>.amazonaws.com/dev/inference \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Tenho problemas para me relacionar com outras pessoas"}'
```

## ğŸ” Modo Demo

Quando o Ollama nÃ£o estÃ¡ disponÃ­vel, o sistema automaticamente entra em modo demo, fornecendo respostas TCC simuladas mas realistas.

## ğŸ“Š Monitoramento

- **CloudWatch Logs**: Logs detalhados de execuÃ§Ã£o
- **MÃ©tricas**: Tempo de inferÃªncia, tokens gerados, uso de memÃ³ria
- **Health Check**: Endpoint para verificar status do sistema

## ğŸ› ï¸ Desenvolvimento

### Estrutura do CÃ³digo

- `lambda_function.py`: Handler principal, roteamento de requests
- `model_manager.py`: Gerenciamento do modelo, integraÃ§Ã£o com Ollama
- `tcc_context.py`: AnÃ¡lise TCC, geraÃ§Ã£o de respostas especializadas
- `utils.py`: ValidaÃ§Ã£o, formataÃ§Ã£o de respostas

### Adicionando Novos Tipos de Resposta

1. Edite `tcc_context.py` para adicionar novos padrÃµes
2. Modifique `model_manager.py` para incluir novas condiÃ§Ãµes
3. Teste com diferentes prompts

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido como exemplo educacional. Use com responsabilidade e sempre consulte profissionais de saÃºde mental para questÃµes sÃ©rias.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## âš ï¸ Disclaimer

Este chatbot Ã© apenas para fins educacionais e de demonstraÃ§Ã£o. NÃ£o substitui terapia profissional. Sempre consulte um terapeuta qualificado para questÃµes de saÃºde mental.